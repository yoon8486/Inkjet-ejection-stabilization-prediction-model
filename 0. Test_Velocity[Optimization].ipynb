{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0c34ea",
   "metadata": {},
   "source": [
    "# 1. Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d3b823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Output_Velocity  Pressure  Voltage          Z\n",
      "0           0.000000       0.0       40   1.517081\n",
      "1           0.000000       1.0       40   1.517081\n",
      "2           0.000000       2.0       40   1.517081\n",
      "3           0.000000       3.0       40   1.517081\n",
      "4           0.433423       0.0       42   1.517081\n",
      "..               ...       ...      ...        ...\n",
      "358         6.099118       1.0       40  17.801203\n",
      "359         5.771092       2.0       40  17.801203\n",
      "360         6.772376       0.0       42  17.801203\n",
      "361         6.660525       1.0       42  17.801203\n",
      "362         6.323895       2.0       42  17.801203\n",
      "\n",
      "[363 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "basic_data = pd.read_csv('c:/lsy_DL/0. TestData_rev8.csv')\n",
    "\n",
    "# \"column1\"과 \"column3\" 열만 가져오기\n",
    "data = basic_data[['Output_Velocity','Pressure','Voltage','Z']]\n",
    "\n",
    "# 가져온 열의 내용 출력\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd1e142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.43342345 0.28823197 0.23015538 0.97009417 0.85824296\n",
      " 0.83673311 0.64852193 1.45299026 1.36910186 1.32500667 1.18626814\n",
      " 2.08860629 2.03590716 1.99826492 1.74767519 2.79520481 2.79950678\n",
      " 2.81994114 2.52633171 3.50395432 3.54482303 3.61580553 3.38672564\n",
      " 4.19334496 4.26755394 4.3869336  4.21270383 0.76037314 0.74639174\n",
      " 0.67648473 0.32479871 1.40674409 1.40351761 1.38953621 1.16475829\n",
      " 0.75499568 1.97567958 1.97783057 2.00364239 1.84984697 1.53042572\n",
      " 2.50267087 2.50159538 2.55214352 2.45427371 2.16281526 2.97158557\n",
      " 2.98986894 3.06192693 2.9952464  2.74143019 3.41361296 3.45340617\n",
      " 3.54052106 3.49535038 3.25336458 3.82982852 3.87177273 3.97179352\n",
      " 3.95673663 3.72658125 4.25142155 4.35574432 4.52352114 4.58805068\n",
      " 4.3008942  1.35404496 1.13679549 0.96149023 0.45063133 1.95094326\n",
      " 1.75950561 1.60571019 1.20562701 0.8948097  2.51342579 2.39297064\n",
      " 2.25423212 1.91330102 1.67669269 3.13936239 2.96835909 2.80811072\n",
      " 2.40372557 3.61903201 3.47921799 3.34370595 3.13183394 3.01890723\n",
      " 4.08579572 3.96641606 3.8470364  3.66420269 3.58354076 4.62569292\n",
      " 4.47619947 4.34176292 4.16645765 4.10623008 5.1526842  5.0257761\n",
      " 4.89886799 4.67946754 4.59557913 5.67107155 5.56997527 5.46135053\n",
      " 5.24947852 5.19677939 6.1754775  6.09374008 5.99479477 5.84745231\n",
      " 5.76679038 6.67450598 6.60997644 6.52286155 6.38734951 6.37982106\n",
      " 1.32930864 1.09592678 0.85071451 0.40330966 1.95524523 1.77241151\n",
      " 1.55946402 1.22928784 1.02494428 2.54784155 2.38436671 2.21981636\n",
      " 1.93373538 1.76810954 3.0662289  2.93394333 2.77907242 2.53708663\n",
      " 2.40695205 3.58784273 3.45985913 3.3221961  3.11462606 3.00169936\n",
      " 4.04922898 3.94383072 3.81046966 3.63839087 3.54804951 4.58374871\n",
      " 4.46006708 4.32132856 4.13311739 4.0739653  5.18494898 5.08062621\n",
      " 4.95156712 4.77841284 4.71388329 5.80120614 5.70441182 5.58825864\n",
      " 5.43446322 5.40327394 6.38950049 6.30131011 6.19698735 6.08621163\n",
      " 6.02383307 6.9993047  6.91218981 6.83152788 6.72720511 6.64331671\n",
      " 7.57469314 7.50801261 7.4391811  7.33270735 7.28000822 8.14470413\n",
      " 8.11028837 8.05866474 7.94681352 7.86292511 1.38308326 1.22713686\n",
      " 0.67325826 1.81112924 1.51321784 0.75069371 2.47685905 2.39727261\n",
      " 1.36587538 3.02858667 2.93286784 2.71561837 2.20260848 3.62440947\n",
      " 3.5211622  3.33402652 2.78552538 4.21162833 4.1030036  3.95458564\n",
      " 3.46308561 4.79024326 4.67624106 4.54825746 4.0073125  5.36455621\n",
      " 5.24732754 5.15483519 4.59773011 5.94209564 5.82916894 5.73990307\n",
      " 5.23657261 6.49812523 6.40563288 6.33357489 5.85067879 0.99698148\n",
      " 0.74531625 1.86705485 1.6756172  1.32285568 2.33704504 2.02300125\n",
      " 1.81005375 3.12645648 2.96298163 2.68120261 2.48976496 3.72012829\n",
      " 3.57493682 3.31896962 3.14904182 4.29981871 4.17828807 3.93522678\n",
      " 3.78358235 4.86337674 4.76120496 4.53750254 4.40414148 5.42801027\n",
      " 5.32798947 5.12579689 5.00749273 5.98511534 5.89262299 5.70978928\n",
      " 5.60331553 6.53361648 6.46048299 6.29378167 6.18838341 1.47987758\n",
      " 2.129475   1.94233932 1.5906533  1.33253511 2.75218511 2.5833328\n",
      " 2.26606254 2.04343561 3.35876284 3.1942125  2.91673545 2.71346739\n",
      " 3.95351015 3.79756375 3.55235148 3.36198932 4.53212508 4.39553754\n",
      " 4.17506159 3.99652985 5.1247214  4.99566231 4.79669621 4.61493799\n",
      " 5.70871379 5.60869299 5.39359451 5.21291178 6.29593265 6.20021383\n",
      " 5.98726633 5.83239542 0.7808075  0.3968567  1.37125284 1.02924625\n",
      " 0.84856352 2.07139841 1.71433492 1.48525504 2.88554617 2.49729341\n",
      " 2.18324962 3.23938318 2.94254727 2.78337439 3.80831867 3.59967314\n",
      " 3.3641403  4.4288778  4.1879675  4.03417208 5.10428705 4.79239424\n",
      " 5.62805186 5.37853761 5.19032644 6.09911754 5.77109235 6.7723758\n",
      " 6.66052458 6.32389545]\n"
     ]
    }
   ],
   "source": [
    "#맨끝에 열을 'Pandas_ unique' 함수로 Taget 데이터로 변환\n",
    "print(pd.unique(data['Output_Velocity']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b49583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         40.          1.51708144]\n",
      " [ 1.         40.          1.51708144]\n",
      " [ 2.         40.          1.51708144]\n",
      " [ 3.         40.          1.51708144]\n",
      " [ 0.         42.          1.51708144]]\n"
     ]
    }
   ],
   "source": [
    "# 특성값 추출 > Input Data\n",
    "data_input=data[['Pressure','Voltage','Z']].to_numpy()\n",
    "print((data_input[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0246f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 열 > Target Data \n",
    "data_target = data['Output_Velocity'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5555a",
   "metadata": {},
   "source": [
    "# 2. AI model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d91d6c",
   "metadata": {},
   "source": [
    "#### Model\n",
    "- Hyperparameter tunning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae83bad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Validation Score: 0.7818594104180787\n",
      "Testing Score: 0.8180008134584711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 훈련 세트와 나머지를 분리\n",
    "train_input, temp_input, train_target, temp_target = train_test_split(\n",
    "    data_input, data_target, test_size=0.4,\n",
    ")\n",
    "\n",
    "# 나머지에서 검증 세트와 테스트 세트를 분리\n",
    "val_input, test_input, val_target, test_target = train_test_split(\n",
    "    temp_input, temp_target, test_size=0.5\n",
    ")\n",
    "\n",
    "# 여기서는 표준화 과정이 빠져 있기 때문에 해당 과정을 추가\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "\n",
    "# 모델 생성 및 훈련\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knr = KNeighborsRegressor(metric='manhattan', n_neighbors=4, weights='distance')\n",
    "knr.fit(train_scaled, train_target)\n",
    "\n",
    "# 모델 평가\n",
    "train_score = knr.score(train_scaled, train_target)\n",
    "val_score = knr.score(val_scaled, val_target)\n",
    "test_score = knr.score(test_scaled, test_target)\n",
    "\n",
    "print(\"Training Score:\", train_score)\n",
    "print(\"Validation Score:\", val_score)\n",
    "print(\"Testing Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f2fa28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9553792395504834\n",
      "MAE: 0.7153501552883741\n",
      "RMSE: 0.9774350308590763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# 예측값 생성 \n",
    "predictions = knr.predict(test_scaled)\n",
    "\n",
    "# 1. 평균 제곱 오차 (MSE)\n",
    "mse = mean_squared_error(test_target, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "# 2. 평균 절대 오차 (MAE)\n",
    "mae = mean_absolute_error(test_target, predictions)\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "# 3. 루트 평균 제곱 오차 (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62c03b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# R-제곱 값을 계산\n",
    "training_r2 = knr.score(train_scaled, train_target)\n",
    "val_r2 = knr.score(val_scaled, val_target)\n",
    "test_r2 = knr.score(test_scaled, test_target)\n",
    "\n",
    "# 데이터를 준비\n",
    "labels = ['Training', 'Validation', 'Test']\n",
    "r2_values = [training_r2, val_r2, test_r2]\n",
    "\n",
    "# 바 차트를 생성\n",
    "plt.bar(labels, r2_values, color=['blue', 'green', 'red'])\n",
    "\n",
    "# 플롯에 레이블을 추가\n",
    "plt.ylabel('R-squared Value')\n",
    "plt.title('R-squared Value for k-NN Regressor')\n",
    "\n",
    "for i, value in enumerate(r2_values):\n",
    "    plt.text(i, value - 0.05 if value > 0.5 else value + 0.03, f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d405e75",
   "metadata": {},
   "source": [
    "# 3. Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb86023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 예측값: [5.99047998 4.24686374 3.15490247 0.86413968 5.01384382 3.89702734\n",
      " 4.96014509 4.52757108 3.87256691 5.82458591 5.75186598 3.01079942\n",
      " 0.85845016 2.74358117 1.45527315 0.31375104 1.5422499  1.59982332\n",
      " 3.89435511 7.04166797 5.93414905 3.62750637 5.9033177  3.1233644\n",
      " 6.2234584  3.0591273  6.38643427 2.03224748 2.94517901 2.07582753\n",
      " 5.40003332 0.55932784 5.95414003 2.23517215 4.19524745 1.01670454\n",
      " 6.10764518 3.82427286 5.9362418  0.92390158 1.37166289 3.14672874\n",
      " 3.00770418 1.89429224 5.37735775 1.18735667 5.46781991 0.66039815\n",
      " 5.12425752 3.96203529 2.00228082 5.67455172 3.82243377 6.41269625\n",
      " 3.59608767 5.77983017 1.74150264 3.0766186  5.44451751 2.44464796\n",
      " 0.2285151  2.3968059  2.00328288 5.32960775 4.7409312  2.33828137\n",
      " 3.36917736 3.94469401 3.0680726  2.07633302 4.4500762  5.64288214\n",
      " 4.19655644]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 예측값 구하기\n",
    "test_predictions = knr.predict(test_scaled)\n",
    "\n",
    "# 예측값 출력\n",
    "print(\"테스트 예측값:\", test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe210d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17460\\1963095908.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 상관 계수를 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_corr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtest_corr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 상관 계수를 계산\n",
    "train_corr, _ = pearsonr(train_predictions, train_target)\n",
    "test_corr, _ = pearsonr(test_predictions, test_target)\n",
    "\n",
    "# 데이터를 준비\n",
    "labels = ['Training', 'Test']\n",
    "corr_values = [train_corr, test_corr]\n",
    "\n",
    "# 바 차트를 생성\n",
    "plt.bar(labels, corr_values, color=['blue', 'green'])\n",
    "\n",
    "# 플롯에 레이블을 추가\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.title('Correlation Coefficient for k-NN Regressor')\n",
    "\n",
    "# 각 바 위에 값들을 추가\n",
    "for i, value in enumerate(corr_values):\n",
    "    plt.text(i, value, f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca341d1",
   "metadata": {},
   "source": [
    "## Prediction Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "eaa2fd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "data = pd.read_csv('c:/lsy_DL/0. TestData_rev8.csv')\n",
    "\n",
    "# \"Pressure\", \"Voltage\", \"Z\" 열만 가져오기\n",
    "new_data_sample = data[['Pressure','Voltage','Z']]\n",
    "\n",
    "# 데이터 샘플을 스케일링\n",
    "new_data_sample_scaled = scaler.transform(new_data_sample)\n",
    "\n",
    "# 스케일링된 데이터 샘플에 대한 예측을 수행\n",
    "prediction = knr.predict(new_data_sample_scaled)\n",
    "\n",
    "# 예측된 값을 'Prediction' 열로 추가\n",
    "new_data_sample['Prediction'] = prediction\n",
    "\n",
    "# DataFrame을 CSV 파일로 저장\n",
    "new_data_sample.to_csv('output_file8.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8777acd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best cross-validation score: 0.8039901765583506\n",
      "Training Score with Best Parameters: 1.0\n",
      "Testing Score with Best Parameters: 0.8396439033328006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, n_jobs=1, verbose=1)\n",
    "\n",
    "# 튜닝 시작\n",
    "grid_search.fit(train_scaled, train_target)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 그 때의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# 최적의 하이퍼파라미터로 훈련된 모델 추출\n",
    "best_knr = grid_search.best_estimator_\n",
    "\n",
    "# 모델 평가\n",
    "train_score = best_knr.score(train_scaled, train_target)\n",
    "test_score = best_knr.score(test_scaled, test_target)\n",
    "\n",
    "print(\"Training Score with Best Parameters:\", train_score)\n",
    "print(\"Testing Score with Best Parameters:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2138d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    # 예: y_true 값이 10 이상일 때의 오차에 2배의 가중치를 부여\n",
    "    penalty = tf.where(y_true > 10, tf.square(y_true - y_pred), 0)\n",
    "    return mse + tf.reduce_mean(penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68506345",
   "metadata": {},
   "source": [
    "# Rev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a24f6bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Output_Velocity  Pressure  Voltage          Z     Error\n",
      "0                0.0       0.0       22   1.517081  0.000000\n",
      "1                0.0       1.0       22   1.517081  0.000000\n",
      "2                0.0       2.0       22   1.517081  0.000000\n",
      "3                0.0       3.0       22   1.517081  0.000000\n",
      "4                0.0       0.0       24   1.517081  0.000000\n",
      "..               ...       ...      ...        ...       ...\n",
      "573              0.0       1.0       52  17.801203  0.000000\n",
      "574              0.0       2.0       52  17.801203  0.173856\n",
      "575              0.0       0.0       54  17.801203  0.000000\n",
      "576              0.0       1.0       54  17.801203  0.000000\n",
      "577              0.0       2.0       54  17.801203  0.000000\n",
      "\n",
      "[578 rows x 5 columns]\n",
      "[0.         0.43342345 0.28823197 0.23015538 0.97009417 0.85824296\n",
      " 0.83673311 0.64852193 1.45299026 1.36910186 1.32500667 1.18626814\n",
      " 2.08860629 2.03590716 1.99826492 1.74767519 2.79520481 2.79950678\n",
      " 2.81994114 2.52633171 3.50395432 3.54482303 3.61580553 3.38672564\n",
      " 4.19334496 4.26755394 4.3869336  4.21270383 0.76037314 0.74639174\n",
      " 0.67648473 0.32479871 1.40674409 1.40351761 1.38953621 1.16475829\n",
      " 0.75499568 1.97567958 1.97783057 2.00364239 1.84984697 1.53042572\n",
      " 2.50267087 2.50159538 2.55214352 2.45427371 2.16281526 2.97158557\n",
      " 2.98986894 3.06192693 2.9952464  2.74143019 3.41361296 3.45340617\n",
      " 3.54052106 3.49535038 3.25336458 3.82982852 3.87177273 3.97179352\n",
      " 3.95673663 3.72658125 4.25142155 4.35574432 4.52352114 4.58805068\n",
      " 4.3008942  1.35404496 1.13679549 0.96149023 0.45063133 1.95094326\n",
      " 1.75950561 1.60571019 1.20562701 0.8948097  2.51342579 2.39297064\n",
      " 2.25423212 1.91330102 1.67669269 3.13936239 2.96835909 2.80811072\n",
      " 2.40372557 3.61903201 3.47921799 3.34370595 3.13183394 3.01890723\n",
      " 4.08579572 3.96641606 3.8470364  3.66420269 3.58354076 4.62569292\n",
      " 4.47619947 4.34176292 4.16645765 4.10623008 5.1526842  5.0257761\n",
      " 4.89886799 4.67946754 4.59557913 5.67107155 5.56997527 5.46135053\n",
      " 5.24947852 5.19677939 6.1754775  6.09374008 5.99479477 5.84745231\n",
      " 5.76679038 6.67450598 6.60997644 6.52286155 6.38734951 6.37982106\n",
      " 1.32930864 1.09592678 0.85071451 0.40330966 1.95524523 1.77241151\n",
      " 1.55946402 1.22928784 1.02494428 2.54784155 2.38436671 2.21981636\n",
      " 1.93373538 1.76810954 3.0662289  2.93394333 2.77907242 2.53708663\n",
      " 2.40695205 3.58784273 3.45985913 3.3221961  3.11462606 3.00169936\n",
      " 4.04922898 3.94383072 3.81046966 3.63839087 3.54804951 4.58374871\n",
      " 4.46006708 4.32132856 4.13311739 4.0739653  5.18494898 5.08062621\n",
      " 4.95156712 4.77841284 4.71388329 5.80120614 5.70441182 5.58825864\n",
      " 5.43446322 5.40327394 6.38950049 6.30131011 6.19698735 6.08621163\n",
      " 6.02383307 6.9993047  6.91218981 6.83152788 6.72720511 6.64331671\n",
      " 7.57469314 7.50801261 7.4391811  7.33270735 7.28000822 8.14470413\n",
      " 8.11028837 8.05866474 7.94681352 7.86292511 1.38308326 1.22713686\n",
      " 0.67325826 1.81112924 1.51321784 0.75069371 2.47685905 2.39727261\n",
      " 1.36587538 3.02858667 2.93286784 2.71561837 2.20260848 3.62440947\n",
      " 3.5211622  3.33402652 2.78552538 4.21162833 4.1030036  3.95458564\n",
      " 3.46308561 4.79024326 4.67624106 4.54825746 4.0073125  5.36455621\n",
      " 5.24732754 5.15483519 4.59773011 5.94209564 5.82916894 5.73990307\n",
      " 5.23657261 6.49812523 6.40563288 6.33357489 5.85067879 0.99698148\n",
      " 0.74531625 1.86705485 1.6756172  1.32285568 2.33704504 2.02300125\n",
      " 1.81005375 3.12645648 2.96298163 2.68120261 2.48976496 3.72012829\n",
      " 3.57493682 3.31896962 3.14904182 4.29981871 4.17828807 3.93522678\n",
      " 3.78358235 4.86337674 4.76120496 4.53750254 4.40414148 5.42801027\n",
      " 5.32798947 5.12579689 5.00749273 5.98511534 5.89262299 5.70978928\n",
      " 5.60331553 6.53361648 6.46048299 6.29378167 6.18838341 1.47987758\n",
      " 2.129475   1.94233932 1.5906533  1.33253511 2.75218511 2.5833328\n",
      " 2.26606254 2.04343561 3.35876284 3.1942125  2.91673545 2.71346739\n",
      " 3.95351015 3.79756375 3.55235148 3.36198932 4.53212508 4.39553754\n",
      " 4.17506159 3.99652985 5.1247214  4.99566231 4.79669621 4.61493799\n",
      " 5.70871379 5.60869299 5.39359451 5.21291178 6.29593265 6.20021383\n",
      " 5.98726633 5.83239542 0.7808075  0.3968567  1.37125284 1.02924625\n",
      " 0.84856352 2.07139841 1.71433492 1.48525504 2.88554617 2.49729341\n",
      " 2.18324962 3.23938318 2.94254727 2.78337439 3.80831867 3.59967314\n",
      " 3.3641403  4.4288778  4.1879675  4.03417208 5.10428705 4.79239424\n",
      " 5.62805186 5.37853761 5.19032644 6.09911754 5.77109235 6.7723758\n",
      " 6.66052458 6.32389545]\n",
      "[[ 0.         22.          1.51708144  0.        ]\n",
      " [ 1.         22.          1.51708144  0.        ]\n",
      " [ 2.         22.          1.51708144  0.        ]\n",
      " [ 3.         22.          1.51708144  0.        ]\n",
      " [ 0.         24.          1.51708144  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "basic_data = pd.read_csv('c:/lsy_DL/0. TestData_rev8.csv')\n",
    "\n",
    "# \"column1\"과 \"column3\" 열만 가져오기\n",
    "data = basic_data[['Output_Velocity','Pressure','Voltage','Z','Error']]\n",
    "\n",
    "# 가져온 열의 내용 출력\n",
    "print(data)\n",
    "\n",
    "#맨끝에 열을 'Pandas_ unique' 함수로 Taget 데이터로 변환\n",
    "print(pd.unique(data['Output_Velocity']))\n",
    "\n",
    "# 특성값 추출 > Input Data\n",
    "data_input=data[['Pressure','Voltage','Z', 'Error']].to_numpy()\n",
    "print((data_input[:5]))\n",
    "\n",
    "# 마지막 열 > Target Data \n",
    "data_target = data['Output_Velocity'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5aa5ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Validation Score: 0.6076328752724377\n",
      "Testing Score: 0.5962722644648553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 훈련 세트와 나머지를 분리\n",
    "train_input, temp_input, train_target, temp_target = train_test_split(\n",
    "    data_input, data_target, test_size=0.4\n",
    ")\n",
    "\n",
    "# 나머지에서 검증 세트와 테스트 세트를 분리\n",
    "val_input, test_input, val_target, test_target = train_test_split(\n",
    "    temp_input, temp_target, test_size=0.5\n",
    ")\n",
    "\n",
    "# 여기서는 표준화 과정이 빠져 있기 때문에 해당 과정을 추가\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "\n",
    "# 모델 생성 및 훈련\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knr = KNeighborsRegressor(metric='euclidean', n_neighbors=3, weights='distance')\n",
    "knr.fit(train_scaled, train_target)\n",
    "\n",
    "# 모델 평가\n",
    "train_score = knr.score(train_scaled, train_target)\n",
    "val_score = knr.score(val_scaled, val_target)\n",
    "test_score = knr.score(test_scaled, test_target)\n",
    "\n",
    "print(\"Training Score:\", train_score)\n",
    "print(\"Validation Score:\", val_score)\n",
    "print(\"Testing Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e972dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 예측값 구하기\n",
    "test_predictions = knr.predict(test_scaled)\n",
    "\n",
    "\n",
    "# 예측값 출력\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "data = pd.read_csv('c:/lsy_DL/0. TestData_rev8.csv')\n",
    "\n",
    "# \"Pressure\", \"Voltage\", \"Z\" 열만 가져오기\n",
    "new_data_sample = data[['Pressure','Voltage','Z', 'Error']]\n",
    "\n",
    "# 데이터 샘플을 스케일링\n",
    "new_data_sample_scaled = scaler.transform(new_data_sample)\n",
    "\n",
    "# 스케일링된 데이터 샘플에 대한 예측을 수행\n",
    "prediction = knr.predict(new_data_sample_scaled)\n",
    "\n",
    "# 예측된 값을 'Prediction' 열로 추가\n",
    "new_data_sample['Prediction'] = prediction\n",
    "\n",
    "# DataFrame을 CSV 파일로 저장\n",
    "new_data_sample.to_csv('output_file8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "193b4945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}\n",
      "Best cross-validation score: 0.5839955173493592\n",
      "Training Score with Best Parameters: 1.0\n",
      "Validation Score: 0.6076328752724377\n",
      "Testing Score with Best Parameters: 0.6396922565514429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, n_jobs=1, verbose=1)\n",
    "\n",
    "# 튜닝 시작\n",
    "grid_search.fit(train_scaled, train_target)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 그 때의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# 최적의 하이퍼파라미터로 훈련된 모델 추출\n",
    "best_knr = grid_search.best_estimator_\n",
    "\n",
    "# 모델 평가\n",
    "train_score = best_knr.score(train_scaled, train_target)\n",
    "val_score = knr.score(val_scaled, val_target)\n",
    "test_score = best_knr.score(test_scaled, test_target)\n",
    "\n",
    "print(\"Training Score with Best Parameters:\", train_score)\n",
    "print(\"Validation Score:\", val_score)\n",
    "print(\"Testing Score with Best Parameters:\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9f808",
   "metadata": {},
   "source": [
    "#  Rev3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d32f20",
   "metadata": {},
   "source": [
    "## 보정계수 찾아내는 코드\n",
    "- 목적함수:SVM_Regression 모델에 대한 보정계수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c97155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epsilon = 1e-10  # 분모가 0이 되는 것을 방지하기 위한 아주 작은 값\n",
    "\n",
    "# 데이터 불러오기\n",
    "basic_data = pd.read_csv('c:/lsy_DL/0. TestData_rev9.csv')\n",
    "data = basic_data[['Output_Velocity','Pressure','Voltage','Viscosity', 'Surface Tension', 'Density']]\n",
    "\n",
    "# 입력, 타겟 데이터 변환\n",
    "data_input = data[['Pressure','Voltage','Viscosity','Surface Tension', 'Density']].to_numpy()\n",
    "data_target = data['Output_Velocity'].to_numpy()\n",
    "\n",
    "# 데이터 분리\n",
    "train_input, temp_input, train_target, temp_target = train_test_split(\n",
    "    data_input, data_target, test_size=0.4, random_state=42\n",
    ")\n",
    "val_input, test_input, val_target, test_target = train_test_split(\n",
    "    temp_input, temp_target, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "\n",
    "# 모델 훈련\n",
    "svm_regressor = SVR(C=100, epsilon=0.1, kernel='rbf')\n",
    "svm_regressor.fit(train_scaled, train_target)\n",
    "\n",
    "# 역 최적화를 위한 목적 함수 정의\n",
    "# epsilon = 1e-10  # 분모가 0이 되는 것을 방지하기 위한 아주 작은 값\n",
    "def inverse_objective_function(x_scaled, y_target):\n",
    "    y_pred = svm_regressor.predict([x_scaled])\n",
    "    # 상대 오차 계산\n",
    "    relative_error = abs(y_pred - y_target) / (abs(y_target) + epsilon)\n",
    "    return relative_error[0]\n",
    "\n",
    "# 주어진 y_target 값에 대해 최적의 x를 찾기\n",
    "y_target = data_target[0]  # 첫 번째 Output_Velocity 값으로 설정\n",
    "x0_scaled = scaler.transform([[1, 1, 1, 1, 1]])  # 초기 추정값. 임의로 설정\n",
    "result = minimize(inverse_objective_function, x0=x0_scaled[0], args=(y_target,))\n",
    "x_optimal_scaled = result.x\n",
    "\n",
    "# 스케일링 된 값을 원래의 값으로 변환\n",
    "x_optimal = scaler.inverse_transform([x_optimal_scaled])\n",
    "\n",
    "print(f\"Optimal x for y_target {y_target} is {x_optimal[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9049116",
   "metadata": {},
   "source": [
    "## 보정계수 찾아내는 코드\n",
    "- 목적함수:다항식 보정공식에 대한 보정계수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab250502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "\n",
    "epsilon = 1e-10  # Avoid division by zero\n",
    "\n",
    "# Data loading\n",
    "basic_data = pd.read_csv('c:/lsy_DL/0. TestData_rev10.csv')\n",
    "data = basic_data[['Output_Velocity','Pressure','Voltage','Viscosity', 'Surface Tension', 'Density']]\n",
    "\n",
    "# Extracting input and target data\n",
    "data_input = data[['Pressure','Voltage','Viscosity','Surface Tension', 'Density']].to_numpy()\n",
    "data_target = data['Output_Velocity'].to_numpy()\n",
    "\n",
    "# Polynomial correction function for 2nd order\n",
    "def polynomial_correction_function(x, coefficients):\n",
    "    a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t = coefficients\n",
    "    return (\n",
    "        a + \n",
    "        b*x[0] + c*x[1] + d*x[2] + e*x[3] + f*x[4] + \n",
    "        g*x[0]**2 + h*x[1]**2 + i*x[2]**2 + j*x[3]**2 + k*x[4]**2 + \n",
    "        l*x[0]*x[1] + m*x[0]*x[2] + n*x[0]*x[3] + o*x[0]*x[4] + \n",
    "        p*x[1]*x[2] + q*x[1]*x[3] + r*x[1]*x[4] + \n",
    "        s*x[2]*x[3] + t*x[2]*x[4]\n",
    "    )\n",
    "\n",
    "# Objective function for optimization\n",
    "def objective_function(coefficients, data_input, data_target):\n",
    "    predictions = np.apply_along_axis(polynomial_correction_function, 1, data_input, coefficients)\n",
    "    relative_errors = np.abs(predictions - data_target) / (np.abs(data_target) + epsilon)\n",
    "    return np.mean(relative_errors)\n",
    "\n",
    "# Initial guess for coefficients\n",
    "initial_coefficients = [1] * 20\n",
    "\n",
    "# Find optimal coefficients\n",
    "result = minimize(objective_function, x0=initial_coefficients, args=(data_input, data_target))\n",
    "optimal_coefficients = result.x\n",
    "\n",
    "# Create a DataFrame to store the optimal coefficients\n",
    "coefficients_df = pd.DataFrame([optimal_coefficients], columns=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't'])\n",
    "\n",
    "# Save the coefficients to a new CSV file\n",
    "coefficients_df.to_csv('c:/lsy_DL/output_file10_5. SVM[Velocity_Factor_Poly].csv', index=False)\n",
    "\n",
    "print(\"Coefficients saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787227e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "\n",
    "epsilon = 1e-10  # Avoid division by zero\n",
    "\n",
    "# Data loading\n",
    "basic_data = pd.read_csv('c:/lsy_DL/0. TestData_rev10_velocity.csv')\n",
    "data_target = basic_data['Output_Velocity'].to_numpy()\n",
    "data_input = basic_data.drop('Output_Velocity', axis=1).to_numpy()\n",
    "\n",
    "# Create polynomial features dynamically\n",
    "def polynomial_correction_function(x, coefficients):\n",
    "    linear_terms = np.dot(coefficients[:len(x)], x)\n",
    "    squared_terms = np.dot(coefficients[len(x):2*len(x)], x**2)\n",
    "    interaction_terms = sum([coefficients[2*len(x) + i] * x[i] * x[j] for i in range(len(x)) for j in range(i+1, len(x))])\n",
    "    return linear_terms + squared_terms + interaction_terms\n",
    "\n",
    "# Objective function for optimization\n",
    "def objective_function(coefficients, data_input, data_target):\n",
    "    predictions = np.apply_along_axis(polynomial_correction_function, 1, data_input, coefficients)\n",
    "    relative_errors = np.abs(predictions - data_target) / (np.abs(data_target) + epsilon)\n",
    "    return np.mean(relative_errors)\n",
    "\n",
    "num_features = data_input.shape[1]\n",
    "# Initial guess for coefficients\n",
    "initial_coefficients = [1] * (2*num_features + (num_features*(num_features-1))//2)\n",
    "\n",
    "# Find optimal coefficients\n",
    "result = minimize(objective_function, x0=initial_coefficients, args=(data_input, data_target))\n",
    "optimal_coefficients = result.x\n",
    "\n",
    "# Create a DataFrame to store the optimal coefficients\n",
    "coefficients_columns = ['Output_Velocity'] + ['a' + str(i) for i in range(len(optimal_coefficients))]\n",
    "coefficients_data = np.concatenate(([data_target[0]], optimal_coefficients)).reshape(1, -1)\n",
    "coefficients_df = pd.DataFrame(coefficients_data, columns=coefficients_columns)\n",
    "\n",
    "# Save the coefficients to a new CSV file\n",
    "coefficients_df.to_csv('c:/lsy_DL/output_file10_5. SVM[Velocity_Factor_Poly1].csv', index=False)\n",
    "\n",
    "print(\"Coefficients saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "\n",
    "epsilon = 1e-10  # Avoid division by zero\n",
    "\n",
    "# Data loading\n",
    "basic_data = pd.read_csv('c:/lsy_DL/0. TestData_rev10_velocity.csv')\n",
    "\n",
    "# Create polynomial features dynamically\n",
    "def polynomial_correction_function(x, coefficients):\n",
    "    linear_terms = np.dot(coefficients[:len(x)], x)\n",
    "    squared_terms = np.dot(coefficients[len(x):2*len(x)], x**2)\n",
    "    interaction_terms = sum([coefficients[2*len(x) + i] * x[i] * x[j] for i in range(len(x)) for j in range(i+1, len(x))])\n",
    "    return linear_terms + squared_terms + interaction_terms\n",
    "\n",
    "# Objective function for optimization\n",
    "def objective_function(coefficients, data_input, data_target):\n",
    "    predictions = np.apply_along_axis(polynomial_correction_function, 1, data_input, coefficients)\n",
    "    relative_errors = np.abs(predictions - data_target) / (np.abs(data_target) + epsilon)\n",
    "    return np.mean(relative_errors)\n",
    "\n",
    "num_features = basic_data.shape[1] - 1  # Subtract one for 'Output_Velocity'\n",
    "# Initial guess for coefficients\n",
    "initial_coefficients = [1] * (2*num_features + (num_features*(num_features-1))//2)\n",
    "\n",
    "coefficients_list = []\n",
    "\n",
    "for i in range(len(basic_data)):\n",
    "    data_target = basic_data.iloc[i]['Output_Velocity']\n",
    "    data_input_values = basic_data.drop('Output_Velocity', axis=1).iloc[i].to_numpy()\n",
    "    \n",
    "    result = minimize(objective_function, x0=initial_coefficients, args=(data_input_values.reshape(1,-1), data_target))\n",
    "    optimal_coefficients = result.x\n",
    "\n",
    "    # Store the Output_Velocity, the related features, and the optimal coefficients for this data point\n",
    "    coefficients_list.append([data_target] + list(data_input_values) + list(optimal_coefficients))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "coefficients_columns = ['Output_Velocity'] + list(basic_data.drop('Output_Velocity', axis=1).columns) + ['a' + str(i) for i in range(len(optimal_coefficients))]\n",
    "coefficients_df = pd.DataFrame(coefficients_list, columns=coefficients_columns)\n",
    "\n",
    "# Save the coefficients to a new CSV file\n",
    "coefficients_df.to_csv('c:/lsy_DL/output_file10_5. SVM[Velocity_Factor_Poly2].csv', index=False)\n",
    "\n",
    "print(\"Coefficients saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edbb343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "\n",
    "epsilon = 1e-10  # Avoid division by zero\n",
    "\n",
    "# Data loading\n",
    "basic_data = pd.read_csv('c:/lsy_DL/0. TestData_rev10_velocity.csv')\n",
    "\n",
    "# Create polynomial features dynamically\n",
    "def polynomial_correction_function(x, coefficients):\n",
    "    num_features = len(x)\n",
    "    linear_terms = np.dot(coefficients[:num_features], x)\n",
    "    squared_terms = np.dot(coefficients[num_features:2*num_features], x**2)\n",
    "    interaction_terms = sum([coefficients[2*num_features + i] * x[i] * x[j] for i in range(num_features) for j in range(i+1, num_features)])\n",
    "    return linear_terms + squared_terms + interaction_terms\n",
    "\n",
    "# Objective function for optimization\n",
    "def objective_function(coefficients, data_input, data_target):\n",
    "    predictions = np.apply_along_axis(polynomial_correction_function, 1, data_input, coefficients)\n",
    "    relative_errors = np.abs(predictions - data_target) / (np.abs(data_target) + epsilon)\n",
    "    return np.mean(relative_errors)\n",
    "\n",
    "num_features = basic_data.shape[1] - 1  # Subtract one for 'Output_Velocity'\n",
    "# Initial guess for coefficients\n",
    "initial_coefficients = [1] * (2*num_features + (num_features*(num_features-1))//2)\n",
    "\n",
    "coefficients_list = []\n",
    "\n",
    "for i in range(len(basic_data)):\n",
    "    data_target = basic_data.iloc[i]['Output_Velocity']\n",
    "    data_input_values = basic_data.drop('Output_Velocity', axis=1).iloc[i].to_numpy()\n",
    "    \n",
    "    result = minimize(objective_function, x0=initial_coefficients, args=(data_input_values.reshape(1,-1), np.array([data_target])))\n",
    "    optimal_coefficients = result.x\n",
    "\n",
    "    # Store the Output_Velocity, the related features, and the optimal coefficients for this data point\n",
    "    coefficients_list.append([data_target] + list(data_input_values) + list(optimal_coefficients))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "coefficients_columns = ['Output_Velocity'] + list(basic_data.drop('Output_Velocity', axis=1).columns) + ['a' + str(i) for i in range(len(optimal_coefficients))]\n",
    "coefficients_df = pd.DataFrame(coefficients_list, columns=coefficients_columns)\n",
    "\n",
    "# Save the coefficients to a new CSV file\n",
    "coefficients_df.to_csv('c:/lsy_DL/output_file10_5. SVM[Velocity_Factor_Poly3].csv', index=False)\n",
    "\n",
    "print(\"Coefficients saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
